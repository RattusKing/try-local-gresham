# robots.txt for Try Local Gresham
User-agent: *
Allow: /
Allow: /business/
Allow: /assets/

# Disallow private/admin areas
Disallow: /api/
Disallow: /dashboard/
Disallow: /admin/
Disallow: /checkout
Disallow: /orders

# Disallow auth pages
Disallow: /*?sign-in
Disallow: /*?sign-up

# Allow crawling of public business and product pages
Allow: /business/*
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.png$
Allow: /*.webp$

# Sitemap
Sitemap: https://trylocalor.com/sitemap.xml

# Crawl-delay for specific bots (optional)
User-agent: Googlebot
Crawl-delay: 0

User-agent: Bingbot
Crawl-delay: 1
